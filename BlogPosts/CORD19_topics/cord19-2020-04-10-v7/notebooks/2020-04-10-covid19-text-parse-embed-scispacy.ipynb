{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse and tokenize using SciSpacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import gensim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = '..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile_date = '2020-04-10-v7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "basedir = ROOT + f'/data/interim/{datafile_date}/'\n",
    "specify_doc_type = 1\n",
    "doc_type = ['smalldocs', 'abstracts'][specify_doc_type]\n",
    "DEBUG_LIMIT = None # 100  # None\n",
    "SPACY_FLAG = True\n",
    "EXPORT_TOKENS = True  # Recommended only for abstracts, unless topic models for full text\n",
    "EXPORT_EMBEDDINGS = True\n",
    "CALCULATE_SIMILARITIES = 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_debug_flag = f'-DEBUG_{DEBUG_LIMIT}' if DEBUG_LIMIT else ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input files\n",
    "datafile = f'{basedir}{datafile_date}-covid19-combined-{doc_type}.jsonl'\n",
    "specter_file = ROOT + f'/data/raw/{datafile_date}/' + 'cord19_specter_embeddings_2020-04-10.csv'\n",
    "# output files\n",
    "embeddir = f'{basedir}embeddings/'\n",
    "embedding_file_template = f'{embeddir}{datafile_date}-covid19-combined-{doc_type}-embedding' + '-{}' + out_debug_flag + '.npy'\n",
    "tokens_file_template = f'{basedir}{datafile_date}-covid19-combined-{doc_type}-tokens' + '-{}' + out_debug_flag + '.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if doc_type == 'smalldocs':\n",
    "    text_column_name = 'text'\n",
    "    process_cols = [text_column_name]\n",
    "elif doc_type == 'abstracts':\n",
    "    text_column_name = 'abstract_clean'\n",
    "    process_cols = [text_column_name]\n",
    "elif doc_type == 'only-abstracts':\n",
    "    text_column_name = 'abstract_clean'\n",
    "    process_cols = [text_column_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_args = {'orient': 'records', 'lines': True}\n",
    "out_json_args = {'date_format': 'iso', **json_args}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(datafile):\n",
    "    print(datafile + ' does not exist')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path_mode = 0o777\n",
    "os.makedirs(embeddir, mode = out_path_mode, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CALCULATE_SIMILARITIES and CALCULATE_SIMILARITIES > 0:\n",
    "    gs_index_tempfile = f'{basedir}tmp/gs_index'\n",
    "    os.makedirs(f'{basedir}tmp', mode = out_path_mode, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in text and create corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.read_json(datafile, **json_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = original_df[text_column_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38022"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SciSpacy parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = original_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG_LIMIT:  # False: \n",
    "    df = df.loc[:DEBUG_LIMIT, :].copy()\n",
    "DEBUG_LIMIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import scispacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SPACY_FLAG:\n",
    "    model_name = \"en_core_sci_lg\"\n",
    "    model = spacy.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_outfile = {}\n",
    "tokens_outfile = {}\n",
    "for name in process_cols:\n",
    "    embedding_outfile[name] = embedding_file_template.format('spacy-' + model_name + '-' + name)\n",
    "    tokens_outfile[name] = tokens_file_template.format('spacy-' + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_embedding(text, model, debug_identifier=None, empty_value=None):\n",
    "    if not text:\n",
    "        return empty_value\n",
    "    try:\n",
    "        doc_vector = model(text).vector\n",
    "        return doc_vector\n",
    "    except:\n",
    "        if debug_identifier:\n",
    "            print('Spacy Embedding error with debug_id=' + str(debug_identifier))\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_embedding_ents_tokens(text, model, debug_identifier=None, empty_value=None):\n",
    "    if not text:\n",
    "        return (empty_value, empty_value, empty_value)\n",
    "    try:\n",
    "        sdoc = model(text)\n",
    "        sdoc_vector = sdoc.vector\n",
    "        sdoc_ents = list(ent.text for ent in sdoc.ents)\n",
    "        sdoc_tokens = list(tok.text for tok in sdoc)\n",
    "        return (sdoc_vector, sdoc_ents, sdoc_tokens)\n",
    "    except:\n",
    "        if debug_identifier:\n",
    "            print('Spacy Embedding error with debug_id=' + str(debug_identifier))\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Spacy Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SPACY_FLAG and not EXPORT_TOKENS and text_column_name in process_cols:\n",
    "    doc_embeddings_text = np.array([spacy_embedding(value, model, empty_value=[])\n",
    "                                      for index, value in df[text_column_name].items()])\n",
    "    doc_embeddings_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38022,)\n"
     ]
    }
   ],
   "source": [
    "if SPACY_FLAG and EXPORT_TOKENS and text_column_name in process_cols:\n",
    "    doc_embeddings_ents_tokens_text = np.array([spacy_embedding_ents_tokens(value, model, empty_value=[])\n",
    "                                      for index, value in df[text_column_name].items()])\n",
    "    \n",
    "    doc_embeddings_text, doc_ents_text, doc_tokens_text = zip(*doc_embeddings_ents_tokens_text)\n",
    "    doc_embeddings_text = np.array(doc_embeddings_text)\n",
    "    print(doc_embeddings_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 200}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check embedding length\n",
    "set([len(x) for x in doc_embeddings_text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.similarities.docsim import Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating scispacy similarities index\n",
      "Reading specter embeddings\n",
      "Calculating specter similarities index\n"
     ]
    }
   ],
   "source": [
    "if CALCULATE_SIMILARITIES and CALCULATE_SIMILARITIES > 0:\n",
    "    num_best = CALCULATE_SIMILARITIES + 1\n",
    "    if SPACY_FLAG:\n",
    "        print('Calculating scispacy similarities index')\n",
    "        spacy_index = Similarity(gs_index_tempfile, doc_embeddings_text, num_features=200, num_best=num_best)\n",
    "    print('Reading specter embeddings')\n",
    "    specter_df = pd.read_csv(specter_file, header=None, index_col=0)\n",
    "    print('Calculating specter similarities index')\n",
    "    specter_index = Similarity(gs_index_tempfile, specter_df.to_numpy(),\n",
    "                               num_features=specter_df.shape[1], num_best=num_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating scispacy similarities\n",
      "Calculating specter similarities\n",
      "Joining specter similarities\n"
     ]
    }
   ],
   "source": [
    "if CALCULATE_SIMILARITIES and CALCULATE_SIMILARITIES > 0:\n",
    "    if SPACY_FLAG:\n",
    "        print('Calculating scispacy similarities')    \n",
    "        df['sims_scispacy_idx'] = [[id_val[0] for id_val in sims[:CALCULATE_SIMILARITIES] if id_val[0] != i]\n",
    "                                for i, sims in enumerate(spacy_index)]\n",
    "        df['sims_scispacy_cord_uid'] = df['sims_scispacy_idx'].apply(lambda lst: [df.loc[i, 'cord_uid'] for i in lst])\n",
    "    print('Calculating specter similarities')\n",
    "    sims_specter_cord_uid_s = pd.Series([[specter_df.index[id_val[0]] for id_val in sims[:CALCULATE_SIMILARITIES]\n",
    "                                     if id_val[0] != i] \n",
    "                              for i, sims in enumerate(specter_index)],\n",
    "                                    index=specter_df.index,\n",
    "                                   name='sims_specter_cord_uid')\n",
    "    print('Joining specter similarities')\n",
    "    sims_specter_cord_uid_s = sims_specter_cord_uid_s[~ sims_specter_cord_uid_s.index.duplicated(keep='last')]\n",
    "    df = df.join(sims_specter_cord_uid_s, on='cord_uid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/interim/2020-04-10-v7/embeddings/2020-04-10-v7-covid19-combined-abstracts-embedding-spacy-en_core_sci_lg-abstract_clean.npy\n"
     ]
    }
   ],
   "source": [
    "if SPACY_FLAG and EXPORT_EMBEDDINGS and text_column_name in process_cols:\n",
    "    np.save(embedding_outfile[text_column_name], doc_embeddings_text)\n",
    "    print(embedding_outfile[text_column_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_column_name = 'abstract_tokens_scispacy'\n",
    "ents_column_name = 'abstract_ent_scispacy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/interim/2020-04-10-v7/2020-04-10-v7-covid19-combined-abstracts-tokens-spacy-en_core_sci_lg.jsonl\n"
     ]
    }
   ],
   "source": [
    "if SPACY_FLAG and EXPORT_TOKENS and text_column_name in process_cols:\n",
    "    new_df = df.copy()\n",
    "    new_df[tokens_column_name] = pd.Series(doc_tokens_text)\n",
    "    new_df[ents_column_name] = pd.Series(doc_ents_text)\n",
    "    new_df.to_json(tokens_outfile[text_column_name], **out_json_args)\n",
    "    print(tokens_outfile[text_column_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
